{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arima35/Creating-anime-characters-using-DCGANs-and-Keras/blob/main/Creating_anime_characters_using_Deep_Convolutional_Generative_Adversarial_Networks_(DCGANs)_and_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIi8BeUW9j86"
      },
      "source": [
        "# **Creating anime characters using Deep Convolutional Generative Adversarial Networks (DCGANs) and Keras**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**yang dibawah buat contoh pembuatan, untuk yang terbaru nanti di push lagi**"
      ],
      "metadata": {
        "id": "ihUhEADhnCJF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouypbeD59j87"
      },
      "source": [
        "Estimated time needed: **60** minutes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMUDQsIs9j87"
      },
      "source": [
        "Imagine if you are in a video game company, your games is famous for its unique characters for every player. With the growth of the player amount, it comes to be a nearly impossible mission to hand plot the characters for millions of players. Your boss plans to keep the unique character creating function in the game, and you need a method to handle the task. <br>\n",
        "\n",
        "__Generative adversarial networks (GANs) might help!__<br>\n",
        "It is a class of machine learning frameworks, first published in June 2014 <a href=https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX0XCEEN/papers/1406.2661.pdf >[1]</a>. <br>\n",
        "GANs could generate new data following the statistic features of the data in the training set. GANs is widely used to generate new and realistic photograph that is authentic to human observers. <br>\n",
        "\n",
        "Convolutional networks (CNNs) has seen huge adoption in computer vision applications. Applying the CNNs to GANs models could help us in building a photo generating model. The combined method is called Deep Convolutional Generative Adversarial Networks (DCGANs). <br>\n",
        "\n",
        "In this lab, we will first focus on simulated data to better understand GANs. <br>\n",
        "Further, we will use the case of massive anime avatar production to introduce how to use DCGANs.<br>\n",
        "__You will create anime characters like the ones below in this project.__\n",
        "\n",
        "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX0XCEEN/images/face_cartton.png\" width=\"700\" alt=\"Skills Network Logo\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tATGntZm9j87"
      },
      "source": [
        "----\n",
        "<center><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX0XCEEN/images/unknown4.jpeg\" width=\"50%\"></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU9xogDl9j88"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNv10qsH9j88"
      },
      "source": [
        "For this lab, we will be using the following libraries:\n",
        "\n",
        "*   [`pandas`](https://pandas.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for managing the data.\n",
        "*   [`numpy`](https://numpy.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for mathematical operations.\n",
        "*   [`sklearn`](https://scikit-learn.org/stable/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for machine learning and machine-learning-pipeline related functions.\n",
        "*   [`seaborn`](https://seaborn.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for visualizing the data.\n",
        "*   [`matplotlib`](https://matplotlib.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for additional plotting tools.\n",
        "*   [`keras`](https://keras.io/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for loading datasets.\n",
        "*   [`tensorflow`](https://www.tensorflow.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for machine learning and neural network related functions.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uq5rrumu9j88"
      },
      "source": [
        "### Installing Required Libraries\n",
        "\n",
        "The following required libraries are pre-installed in the Skills Network Labs environment. However, if you run this notebook commands in a different Jupyter environment (e.g. Watson Studio or Ananconda), you will need to install these libraries by removing the `#` sign before `!mamba` in the code cell below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "j-B0Kz0L47rj",
        "outputId": "a9a091b7-6138-4fab-86d9-88343d170ab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (75.1.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-75.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.45.1)\n",
            "Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-75.6.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.1.0\n",
            "    Uninstalling setuptools-75.1.0:\n",
            "      Successfully uninstalled setuptools-75.1.0\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pip-24.3.1 setuptools-75.6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "setuptools"
                ]
              },
              "id": "33f38d49e5894808989d9cd7cd86aaa8"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install --upgrade pip setuptools wheel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIhU1vuI9j89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abf7b03c-f68d-48cb-9359-7c87c9d1c30b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.21.4 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.21.4 which is incompatible.\n",
            "arviz 0.20.0 requires numpy>=1.23.0, but you have numpy 1.21.4 which is incompatible.\n",
            "arviz 0.20.0 requires pandas>=1.5.0, but you have pandas 1.3.4 which is incompatible.\n",
            "astropy 6.1.7 requires numpy>=1.23, but you have numpy 1.21.4 which is incompatible.\n",
            "bigframes 1.27.0 requires matplotlib>=3.7.1, but you have matplotlib 3.5.0 which is incompatible.\n",
            "bigframes 1.27.0 requires numpy>=1.24.0, but you have numpy 1.21.4 which is incompatible.\n",
            "bigframes 1.27.0 requires pandas>=1.5.3, but you have pandas 1.3.4 which is incompatible.\n",
            "bigframes 1.27.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.0.2 which is incompatible.\n",
            "chex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.21.4 which is incompatible.\n",
            "contourpy 1.3.1 requires numpy>=1.23, but you have numpy 1.21.4 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires numpy<3.0a0,>=1.23, but you have numpy 1.21.4 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.3.4 which is incompatible.\n",
            "flax 0.8.5 requires numpy>=1.22, but you have numpy 1.21.4 which is incompatible.\n",
            "geopandas 1.0.1 requires numpy>=1.22, but you have numpy 1.21.4 which is incompatible.\n",
            "geopandas 1.0.1 requires pandas>=1.4.0, but you have pandas 1.3.4 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.3.4 which is incompatible.\n",
            "ibis-framework 9.2.0 requires numpy<3,>=1.23.2, but you have numpy 1.21.4 which is incompatible.\n",
            "ibis-framework 9.2.0 requires pandas<3,>=1.5.3, but you have pandas 1.3.4 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.21.4 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.21.4 which is incompatible.\n",
            "langchain 0.3.11 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 1.21.4 which is incompatible.\n",
            "mizani 0.13.1 requires numpy>=1.23.5, but you have numpy 1.21.4 which is incompatible.\n",
            "mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 1.3.4 which is incompatible.\n",
            "mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.0.2 which is incompatible.\n",
            "nibabel 5.3.2 requires numpy>=1.22, but you have numpy 1.21.4 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 1.21.4 which is incompatible.\n",
            "numexpr 2.10.2 requires numpy>=1.23.0, but you have numpy 1.21.4 which is incompatible.\n",
            "nx-cugraph-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.21.4 which is incompatible.\n",
            "pandas-stubs 2.2.2.240909 requires numpy>=1.23.5, but you have numpy 1.21.4 which is incompatible.\n",
            "plotnine 0.14.3 requires matplotlib>=3.8.0, but you have matplotlib 3.5.0 which is incompatible.\n",
            "plotnine 0.14.3 requires numpy>=1.23.5, but you have numpy 1.21.4 which is incompatible.\n",
            "plotnine 0.14.3 requires pandas>=2.2.0, but you have pandas 1.3.4 which is incompatible.\n",
            "pylibraft-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.21.4 which is incompatible.\n",
            "rmm-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.21.4 which is incompatible.\n",
            "scikit-image 0.24.0 requires numpy>=1.23, but you have numpy 1.21.4 which is incompatible.\n",
            "statsmodels 0.14.4 requires numpy<3,>=1.22.3, but you have numpy 1.21.4 which is incompatible.\n",
            "statsmodels 0.14.4 requires pandas!=2.1.0,>=1.4, but you have pandas 1.3.4 which is incompatible.\n",
            "tensorflow 2.17.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.21.4 which is incompatible.\n",
            "tensorstore 0.1.69 requires numpy>=1.22.0, but you have numpy 1.21.4 which is incompatible.\n",
            "xarray 2024.10.0 requires numpy>=1.24, but you have numpy 1.21.4 which is incompatible.\n",
            "xarray 2024.10.0 requires pandas>=2.1, but you have pandas 1.3.4 which is incompatible.\n",
            "xarray-einstats 0.8.0 requires numpy>=1.23, but you have numpy 1.21.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n",
        "!pip install -q pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 scikit-learn==1.0.2\n",
        "\n",
        "# Note: If your environment doesn't support \"!mamba install\", use \"!pip install\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "Q-Zx7iN0FHck",
        "outputId": "1d53bbf7-f9ea-49e4-efe8-b2b5115d6797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.25.2\n",
            "  Downloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Downloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.4\n",
            "    Uninstalling numpy-1.21.4:\n",
            "      Successfully uninstalled numpy-1.21.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "arviz 0.20.0 requires pandas>=1.5.0, but you have pandas 1.3.4 which is incompatible.\n",
            "bigframes 1.27.0 requires matplotlib>=3.7.1, but you have matplotlib 3.5.0 which is incompatible.\n",
            "bigframes 1.27.0 requires pandas>=1.5.3, but you have pandas 1.3.4 which is incompatible.\n",
            "bigframes 1.27.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.0.2 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.3.4 which is incompatible.\n",
            "geopandas 1.0.1 requires pandas>=1.4.0, but you have pandas 1.3.4 which is incompatible.\n",
            "ibis-framework 9.2.0 requires pandas<3,>=1.5.3, but you have pandas 1.3.4 which is incompatible.\n",
            "mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 1.3.4 which is incompatible.\n",
            "mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.0.2 which is incompatible.\n",
            "plotnine 0.14.3 requires matplotlib>=3.8.0, but you have matplotlib 3.5.0 which is incompatible.\n",
            "plotnine 0.14.3 requires pandas>=2.2.0, but you have pandas 1.3.4 which is incompatible.\n",
            "statsmodels 0.14.4 requires pandas!=2.1.0,>=1.4, but you have pandas 1.3.4 which is incompatible.\n",
            "xarray 2024.10.0 requires pandas>=2.1, but you have pandas 1.3.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.25.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "fd650aa326ff4a5f9b79437e70b82d6f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "!pip install --upgrade numpy==1.25.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLWFCnjd9j89"
      },
      "source": [
        "The following required libraries are __not__ pre-installed in the Skills Network Labs environment. __You will need to run the following cell__ to install them:\n",
        "\n",
        "_You need ~30 seconds to install._\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWfFttK_9j89",
        "outputId": "91da9fb9-b068-47c5-da76-11b5ddd70b42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Collecting skillsnetwork\n",
            "  Downloading skillsnetwork-0.21.9-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from skillsnetwork) (7.34.0)\n",
            "Collecting ipywidgets<9,>=8 (from skillsnetwork)\n",
            "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from skillsnetwork) (2.32.3)\n",
            "Collecting comm>=0.1.3 (from ipywidgets<9,>=8->skillsnetwork)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=8->skillsnetwork) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.12 (from ipywidgets<9,>=8->skillsnetwork)\n",
            "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=8->skillsnetwork) (3.0.13)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (75.6.0)\n",
            "Collecting jedi>=0.16 (from ipython->skillsnetwork)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->skillsnetwork) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->skillsnetwork) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->skillsnetwork) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->skillsnetwork) (2024.8.30)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->skillsnetwork) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->skillsnetwork) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->skillsnetwork) (0.2.13)\n",
            "Downloading skillsnetwork-0.21.9-py3-none-any.whl (26 kB)\n",
            "Downloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
            "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: widgetsnbextension, jedi, comm, ipywidgets, skillsnetwork\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.10\n",
            "    Uninstalling widgetsnbextension-3.6.10:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 1.27.0 requires matplotlib>=3.7.1, but you have matplotlib 3.5.0 which is incompatible.\n",
            "bigframes 1.27.0 requires pandas>=1.5.3, but you have pandas 1.3.4 which is incompatible.\n",
            "bigframes 1.27.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed comm-0.2.2 ipywidgets-8.1.5 jedi-0.19.2 skillsnetwork-0.21.9 widgetsnbextension-4.0.13\n"
          ]
        }
      ],
      "source": [
        "%pip install tqdm skillsnetwork"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS7ZgKw09j89"
      },
      "source": [
        "Run the following upgrade and then **RESTART YOUR KERNEL**. Make sure the version of tensorflow imported below is **no less than 2.9.0**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DgGfUR439j89",
        "outputId": "82f60e7b-416a-450d-900a-d8bdd5219ce1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.6.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow)\n",
            "  Downloading numpy-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.3/615.3 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, tensorboard, tensorflow\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "arviz 0.20.0 requires pandas>=1.5.0, but you have pandas 1.3.4 which is incompatible.\n",
            "bigframes 1.27.0 requires matplotlib>=3.7.1, but you have matplotlib 3.5.0 which is incompatible.\n",
            "bigframes 1.27.0 requires pandas>=1.5.3, but you have pandas 1.3.4 which is incompatible.\n",
            "bigframes 1.27.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.0.2 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.3.4 which is incompatible.\n",
            "cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.0.2 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.0.2 which is incompatible.\n",
            "geopandas 1.0.1 requires pandas>=1.4.0, but you have pandas 1.3.4 which is incompatible.\n",
            "ibis-framework 9.2.0 requires pandas<3,>=1.5.3, but you have pandas 1.3.4 which is incompatible.\n",
            "langchain 0.3.11 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 2.0.2 which is incompatible.\n",
            "mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 1.3.4 which is incompatible.\n",
            "mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.0.2 which is incompatible.\n",
            "plotnine 0.14.3 requires matplotlib>=3.8.0, but you have matplotlib 3.5.0 which is incompatible.\n",
            "plotnine 0.14.3 requires pandas>=2.2.0, but you have pandas 1.3.4 which is incompatible.\n",
            "pytensor 2.26.4 requires numpy<2,>=1.17.0, but you have numpy 2.0.2 which is incompatible.\n",
            "scipy 1.10.1 requires numpy<1.27.0,>=1.19.5, but you have numpy 2.0.2 which is incompatible.\n",
            "statsmodels 0.14.4 requires pandas!=2.1.0,>=1.4, but you have pandas 1.3.4 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.18.0 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.0.2 which is incompatible.\n",
            "xarray 2024.10.0 requires pandas>=2.1, but you have pandas 1.3.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.0.2 tensorboard-2.18.0 tensorflow-2.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qgi7rLI39j8-"
      },
      "source": [
        "### Importing Required Libraries\n",
        "\n",
        "_We recommend you import all required libraries in one place (here):_\n",
        "\n",
        "_You need ~1 minute to import._\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MkFw2my9j8-",
        "outputId": "9ca9b559-02f7-4e44-a3bc-b1b2e89aaec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow version: 2.18.0\n",
            "skillsnetwork version: 0.21.9\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv2DTranspose, BatchNormalization, ReLU, Conv2D, LeakyReLU\n",
        "import time\n",
        "\n",
        "import keras\n",
        "from tqdm import tqdm\n",
        "from IPython import display\n",
        "import skillsnetwork\n",
        "\n",
        "print(f\"tensorflow version: {tf.__version__}\")\n",
        "print(f\"skillsnetwork version: {skillsnetwork.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxW-eDgQ9j8-"
      },
      "source": [
        "### Defining Helper Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQmsuPVg9j8-"
      },
      "outputs": [],
      "source": [
        "# Fungsi untuk memplot distribusi data\n",
        "def plot_distribution(real_data, generated_data, discriminator=None, density=True):\n",
        "    plt.hist(real_data.numpy(), 50, density=density, facecolor='g', alpha=0.75, label='real data')\n",
        "    plt.hist(generated_data.numpy(), 50, density=density, facecolor='r', alpha=0.75,label='generated data q(z)')\n",
        "\n",
        "    if discriminator:\n",
        "        max_ = np.max([int(real_data.numpy().max()), int(generated_data.numpy().max())])\n",
        "        min_ = np.min([int(real_data.numpy().min()), int(generated_data.numpy().min())])\n",
        "        x = np.linspace(min_, max_, 1000).reshape(-1, 1)\n",
        "        plt.plot(x, tf.math.sigmoid(discriminator(x, training=False).numpy()), label='discriminator', color='k')\n",
        "        plt.plot(x, 0.5 * np.ones(x.shape), label='0.5', color='b')\n",
        "        plt.xlabel('x')\n",
        "\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Fungsi untuk menampilkan gambar dalam array\n",
        "def plot_array(X, title=\"\"):\n",
        "    plt.rcParams['figure.figsize'] = (20, 20)\n",
        "\n",
        "    for i, x in enumerate(X[0:5]):\n",
        "        x = x.numpy()\n",
        "        max_ = x.max()\n",
        "        min_ = x.min()\n",
        "        xnew = np.uint8(255 * (x - min_) / (max_ - min_))\n",
        "        plt.subplot(1, 5, i + 1)\n",
        "        plt.imshow(xnew)\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8u8_hvp9j8-"
      },
      "source": [
        "----\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO4MR4wp9j8-"
      },
      "source": [
        "## Basic: Generative Adversarial Networks (GANs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTeSy_fG9j8_"
      },
      "source": [
        "### Introduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpCMr-am9j8_"
      },
      "source": [
        "__Generative Adversarial Networks (GANs)__ are generative models that convert random samples of one distribution into another distribution. They have several applications, like the following:\n",
        "\n",
        "*  Generate Examples for Image Datasets\n",
        "*  Generate Photographs of Human Faces\n",
        "*  Generate Realistic Photographs\n",
        "*  Generate Cartoon Characters\n",
        "*  Image-to-Image Translation\n",
        "*  Text-to-Image Translation\n",
        "*  Face Frontal View Generation\n",
        "*  Generate New Human Poses\n",
        "*  Face Aging\n",
        "*  Photo Blending\n",
        "*  Super Resolution\n",
        "*  Photo Inpainting\n",
        "*  Clothing Translation\n",
        "*  Video Prediction\n",
        "\n",
        "In this GANs section of the Lab, we will use a toy example to help understand the __basic theoretical principles__ behind GANs. The original form of GANs consisted of a __discriminator__ and a __generator__; let's use the analogy of a currency forger and the police.\n",
        "\n",
        "The Generator is the currency forger, and the output is the counterfeit, for example, a 100-dollar bill. The discriminator is analogous to the police taking the counterfeit and trying to determine if it's real by comparing it to a real $100 bill. In real life, if the counterfeit is easy to detect, the forger will adapt; conversely, the police will also improve; GANs emulate this game of cat and mouse.  \n",
        "\n",
        "<center><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX0XCEEN/images/General%20diagram.png\" alt=\"generator image\" width=\"700px\"></center>\n",
        "\n",
        "What makes GANs interesting is that the __discriminator and generator continuously improve__ each other by a well-formulated cost function that backpropagates the errors. GANs are a family of algorithms that use _learning by comparison_. In the lab, we will review the original formulation and use a simulated dataset. We will also point you to some more advanced methods and issues you will encounter with the real datasets for the next lab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3Rtw-hJ9j8_"
      },
      "source": [
        "### Toy Data\n",
        "\n",
        "Consider the following data, $\\mathbf{x}$, that is normally distributed $\\mathbf{x} \\sim \\mathcal{N}(\\mathbf{x}|10,1) $ with a mean of 10 and a standard deviation of 1. Now we would like to randomly sample data from this distribution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaHTwnXY9j8_",
        "outputId": "c7358cbf-84fb-4609-e375-837ceea44cfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean: 9.972308\n",
            "standard deviation: 1.0042675\n"
          ]
        }
      ],
      "source": [
        "mean = [10]\n",
        "cov = [[1]]\n",
        "X = tf.random.normal((5000,1),mean=10,stddev=1.0)\n",
        "\n",
        "print(\"mean:\",np.mean(X))\n",
        "print(\"standard deviation:\",np.std(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ME3k_8mr9j8_"
      },
      "source": [
        "We also have the data sample, z, which is also normally distributed $\\mathbf{z} \\sim \\mathcal{N}(\\mathbf{z}|0,2) $, with mean of 0 and a standard deviation of 2:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TE6HMhLl9j8_"
      },
      "outputs": [],
      "source": [
        "Z = tf.random.normal((5000,1),mean=0,stddev=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nRdxq7H9j8_",
        "outputId": "3af1a84d-e8cd-44e0-fb11-90395fd27220"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean: 0.008829478\n",
            "standard deviation: 2.01729\n"
          ]
        }
      ],
      "source": [
        "print(\"mean:\",np.mean(Z))\n",
        "print(\"standard deviation:\",np.std(Z))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XavaQmXr9j9A"
      },
      "source": [
        "Let's compare the two distributions:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNet3AKU9j9A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "36bec1f5-8afd-4c7d-f8a7-d9d82fb12287"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot_distribution(X,Z,discriminator=None,density=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q68Evqr29j9A"
      },
      "source": [
        ":Let's create our first generative model by adding 10 to every sample of $z$. We will call the result $\\hat{\\mathbf{x}}$  as it's an approximation of $\\mathbf{x}$. It is not too difficult to show that $\\hat{\\mathbf{x}} \\sim \\mathcal{N}(\\mathbf{x}|10,1)$.Xhat=Z+10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPoyk8lV9j9A"
      },
      "outputs": [],
      "source": [
        "Xhat=Z+10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz1qWxlO9j9A"
      },
      "source": [
        "We see that the mean and standard deviation are almost identical\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkHnDAsj9j9A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4024b69-abb7-45ae-92d6-8bedaadde472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean: 10.00883\n",
            "standard deviation: 2.01729\n"
          ]
        }
      ],
      "source": [
        "print(\"mean:\",np.mean(Xhat))\n",
        "print(\"standard deviation:\",np.std(Xhat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMpDqu_o9j9B"
      },
      "source": [
        "Similarly for the histograms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "MF9gCh2y9j9B",
        "outputId": "1219b62f-9648-4034-e3e7-0be5b4cc3618"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "plot_distribution(X,Xhat,discriminator=None,density=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytFN-VIw9j9C"
      },
      "source": [
        "In the case above, since we just add 10 to the latent variable $z$, we transform $z$ using a deterministic function. We can call this an implicit generative model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BPcCNt79j9C"
      },
      "source": [
        "### The Generator\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prHhn7Yi9j9C"
      },
      "source": [
        "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX0XCEEN/images/Unknown.png\" width=\"300px\">\n",
        "\n",
        "There are two networks involved in a GAN, the Generator and the Discriminator. Let's understand the Generator network first.\n",
        "\n",
        "The Generator is a neural network denoted by $G$; the idea is that a neural network can approximate any function (by the [Universal Approximation Theorem](https://en.wikipedia.org/wiki/Universal_approximation_theorem?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMGPXX0XCEEN72-2022-01-01)), so you should be able to generate data samples from any type of distribution.\n",
        "\n",
        "Our goal is to convert the samples, $\\mathbf{z}$, to one that approximates $\\hat{\\mathbf{x}}$,  i.e $\\hat{\\mathbf{x}}=G(\\mathbf{z})$. Let's build a simple Generator $G(\\mathbf{z})=\\mathbf{W}^{T}\\mathbf{z}+\\mathbf{b} $ using Keras.\n",
        "\n",
        "The following is a function that outputs a generator using Kera's Sequential model object.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7-YnysT9j9C"
      },
      "outputs": [],
      "source": [
        "def make_generator_model():\n",
        "    generator = tf.keras.Sequential()\n",
        "    generator.add(layers.Dense(1))\n",
        "    return generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlCIsGOn9j9C"
      },
      "source": [
        "We can use the Generator to convert $\\mathbf{z}$ and make a prediction $\\hat{\\mathbf{x}}$, and display the histogram of the distributions of $\\hat{\\mathbf{x}}$ and $\\mathbf{x}$. As the model is not trained, the trained distributions are quite different:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EBifIo39j9C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "a5c23447-7033-4983-8f2d-eb7b9bdc29f7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "generator=make_generator_model()\n",
        "\n",
        "Xhat = generator(Z, training=False)\n",
        "plot_distribution(real_data=X,generated_data=Xhat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_Wpd_Wu9j9D"
      },
      "source": [
        "We will discuss the use of the parameter ```training=False``` later on.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX_3FYw_9j9D"
      },
      "source": [
        "### The Discriminator\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcKMBxzH9j9D"
      },
      "source": [
        "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX0XCEEN/images/Unknown1.png\" width=\"300px\">\n",
        "\n",
        "The discriminator $D(\\mathbf{x})$ is a neural network that learns to distinguish between actual and generated samples. The simplest Discriminator is a simple logistic regression function. Let's create a discriminator in Keras with one Dense layer; we leave the logistic function out as it will be incorporated in the cost function, which is the convention in Keras.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erKVwmn79j9D"
      },
      "outputs": [],
      "source": [
        "def make_discriminator_model():\n",
        "    discriminator=tf.keras.Sequential()\n",
        "    discriminator.add(layers.Dense(1))\n",
        "    return discriminator\n",
        "\n",
        "discriminator=make_discriminator_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OLSphkP9j9D"
      },
      "source": [
        "The discriminator and generator are randomly initialized, but we can plot the output of each and compare it to the true data distribution, with the generated data in red and the real data in green, and the logistic function as a function of the x axis. We also include the threshold. If the output of the logistic function is less than 0.5, the sample is classified as generated data; conversely, if the output is greater than 0.5, the sample will be classified as data that came from the real distribution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2Q9bKy_9j9D"
      },
      "outputs": [],
      "source": [
        "plot_distribution(real_data=X,generated_data=Xhat,discriminator=discriminator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F2istTa9j9E"
      },
      "source": [
        "Applying the sigmoid function to the discriminator output, we get the probabilites that the samples belong to the real distribution. We can count the number of true samples that the discriminator correctly classifies.\n",
        "\n",
        "For the real data, the discriminator successfully assigns a probability greater than 0.5 for all 5000 samples:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IDC1g9k9j9E"
      },
      "outputs": [],
      "source": [
        "py_x=tf.math.sigmoid(discriminator(X,training=False))\n",
        "np.sum(py_x>0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNPn5JS89j9E"
      },
      "source": [
        "For the generated data, only a part of the 5000 samples are classified as having more than 50% chance of coming from the real distribution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_Lunsyb9j9E"
      },
      "outputs": [],
      "source": [
        "py_x=discriminator(Xhat)\n",
        "np.sum(py_x>0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tdn2So1l9j9E"
      },
      "source": [
        "We can also use the following to find the average value of the sigmoid function for all the samples.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GAQiVcD9j9E"
      },
      "outputs": [],
      "source": [
        "def get_accuracy(X,Xhat):\n",
        "    total=0\n",
        "    py_x=tf.math.sigmoid(discriminator(X,training=False))\n",
        "    total=np.mean(py_x)\n",
        "    py_x=tf.math.sigmoid(discriminator(Xhat,training=False))\n",
        "    total+=np.mean(py_x)\n",
        "    return total/2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lwsi8uCE9j9F"
      },
      "source": [
        "In many cases, we can instead study the difference in the distribution; in this case, the discriminator is called a <a href='https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX0XCEEN/papers/2107.06700.pdf'>Critic</a>, a real-valued function.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2X1dBAt9j9F"
      },
      "source": [
        "### The Loss Function GANs (Optional)\n",
        "GANs convert an unsupervised learning problem to a supervised one. Instead of formulating the problem like a two-player minimax game with a value function like in <a href=https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX0XCEEN/papers/1406.2661.pdf >[1]</a>, we can treat the problem of maximizing the familiar log-likelihood of the logistic function analogous to minimizing the cross-entropy loss, then incorporate the generator and discriminator.\n",
        "\n",
        "___Discriminator___\n",
        "\n",
        "In order to train the GANS, we start off with standard maximization of the likelihood for the discriminator for the standard dataset $\\mathcal{D}=\\{{(x_1, y_1), ..., (x_N, y_N)}\\}$:\n",
        "\n",
        "$$V(D)=\\sum_{n=1}^N \\left( y_n \\ln(D(\\mathbf{x}_n))+(1-y_n) \\ln(1-D(\\mathbf{x}_n))\\right)$$\n",
        "\n",
        "Where $y=1$ for samples from the true distribution and $y=0$ for samples from the generator. The goal is to maximize this term with respect to $D$:\n",
        "\n",
        "$$max_{D}(V(D))$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h17qhqpp9j9F"
      },
      "source": [
        "To also incorporate the generated samples, we augment the right side of the equation with the generated $k$th sample $\\hat{\\mathbf{x}}_k$. As they are not part of the dataset $k \\notin \\mathcal{D} $, we have to include a second summation where $y=0$. Finally, combining the cases of $y=1$ and $y=0$, we get:\n",
        "\n",
        "$$V(D)=\\sum_{ n\t\\in \\mathcal{D}}  \\ln(D(\\mathbf{x}_n))+\\sum_{k \t\\notin \\mathcal{D}} \\ln(1-D(\\hat{\\mathbf{x}}_k) ) $$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYnwxcYA9j9F"
      },
      "source": [
        "___Generator___\n",
        "\n",
        "For the generator we simply replace $\\hat{\\mathbf{x}}_k$ with the $G(\\mathbf{z}_k)$ .\n",
        "\n",
        "\n",
        "$$V(G,D)=\\sum_{n\t\\in \\mathcal{D}} \\ln(D(\\mathbf{x}_n))+\\sum_{k \t\\notin \\mathcal{D}} \\ln(1-D(G(\\mathbf{z}_k))) $$\n",
        "\n",
        "As this is a density estimation problem, it is common to replace the summation with the expected value like in <a href=https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX0XCEEN/papers/1406.2661.pdf >[1]</a>. We replace the summations with an expectation where $p(\\mathbf{x})$ is the true distribution and $p(\\mathbf{z})$ is the distribution of $\\mathbf{z}$.\n",
        "\n",
        "\n",
        "$$V(D,G)=\\mathbb{E}_{x\\sim p(\\mathbf{x})} \\ln(D(\\mathbf{x})) + \\mathbb{E}_{\\mathbf{z} \\sim p(\\mathbf{z})} \\ln(1-D(G(\\mathbf{z}) )) $$\n",
        "\n",
        "As we are trying to trick the discriminator, we would like to find a $G$ that minimize the above expression, such as:\n",
        "\n",
        "$$min_{G} max_{D} V(D,G)$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9c2NHkL9j9F"
      },
      "source": [
        "### Training GANs\n",
        "\n",
        "GANs are quite difficult to train, even for a simple example. Let's start off with training the generator in practice.\n",
        "\n",
        "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX0XCEEN/images/unknown3.jpeg\" width=\"500px\">\n",
        "\n",
        "___Training Generator___\n",
        "\n",
        "$log(1 − D(G(\\mathbf{z})))$ is difficult to work with as $D(G(\\mathbf{z}))$ is near one or zero for the first few iterations. This is because the generator is not yet properly trained, and the discriminator can easily distinguish between the generated and actual samples. Therefore we maximize $log(D(G(\\mathbf{z}_k)) )$.\n",
        "\n",
        "Although the output of the generator passes through the discriminator, we do not update the generator in the optimization step, hence we set the parameter ```training=False``` in the actual training steps.\n",
        "\n",
        "\n",
        "Instead of maximizing the term, we can take the negative and minimize it. The resultant expression can be calculated in Keras using the cross-entropy loss where all the target values are set to one:\n",
        "\n",
        "$$\\sum_{k \t\\notin \\mathcal{D}} log(1 - D(G(\\mathbf{z}_k)) )$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5073Irh9j9F"
      },
      "outputs": [],
      "source": [
        "# This method returns a helper function to compute crossentropy loss\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "def generator_loss(Xhat):\n",
        "    return cross_entropy(tf.ones_like(Xhat), Xhat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAxEdIP39j9G"
      },
      "source": [
        "___Training Discriminator___\n",
        "\n",
        "We can also use the cross-entropy to train the discriminator; we simply multiply $V(G,D)$ by a negative number, set $y=0$ for the generated values and $y=1$ for the real values. We do not update the generator parameters.\n",
        "\n",
        "$$V(G)=\\sum_{n\t\\in \\mathcal{D}} (\\ln(D(\\mathbf{x}_n)))+\\sum_{k \t\\notin \\mathcal{D}} \\ln(1-D(G(\\mathbf{z}_k) )) $$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XGrbcXW9j9G"
      },
      "source": [
        "The first term is the real loss and the second is the fake loss in Keras.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbKoXhI19j9G"
      },
      "outputs": [],
      "source": [
        "def discriminator_loss(X, Xhat):\n",
        "    real_loss = cross_entropy(tf.ones_like(X), X)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(Xhat), Xhat)\n",
        "    total_loss = 0.5*(real_loss + fake_loss)\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWfQdy3K9j9G"
      },
      "source": [
        "We create the optimizer for the discriminator and generator:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9DSLY4Q9j9G"
      },
      "outputs": [],
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(5e-1,beta_1=0.5,beta_2=0.8)\n",
        "\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(5e-1,beta_1=0.5, beta_2=0.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCb0xVVA9j9G"
      },
      "source": [
        "We now train the model; as the dataset is small, we will use batch gradient descent.\n",
        "\n",
        "For each iteration we will generate $M$ real examples $\\{\\mathbf{x}_{1}, ...,\\mathbf{x}_{M}\\}$, these are from the generating distribution $p(\\mathbf{x})$. This would be our actual dataset if we used real data.  \n",
        "\n",
        "We will then generate a sample batch of $M$ noise samples $\\{\\mathbf{z}_{1}, ...,\\mathbf{z}_{M}\\}$ from noise prior $p(\\mathbf{z})$ and convert the result to a generated image using the generator $\\{\\hat{\\mathbf{x}}_{1}, ...,\\hat{\\mathbf{x}}_{M}\\}$.\n",
        "\n",
        "We determine the output of the discriminator for both the real and generated samples. We calculate the loss and then update the discriminator and generator through their respective stochastic gradients.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySE2TAVC9j9G"
      },
      "source": [
        "The convergence of GAN training is a subject in itself. But let's explore a method that works for this simple dataset. Intuitively, we know that if our generated data is identical to our actual data, the probability of correctly classifying is random. Therefore if the generated and actual data are of equal proportion, $D(\\mathbf{x}_n)=0.5$ and $D(\\hat{\\mathbf{x}}_n)=0.5$.  \n",
        "\n",
        "We only display iterations where the average discriminator output gets closer to 50% for both the generated data and actual data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URlWqMOv9j9H"
      },
      "outputs": [],
      "source": [
        "#parameters for training\n",
        "epochs=20\n",
        "BATCH_SIZE=5000\n",
        "noise_dim=1\n",
        "epsilon=100\n",
        "\n",
        "\n",
        "#discrimator and gernerator\n",
        "tf.random.set_seed(0)\n",
        "discriminator=make_discriminator_model()\n",
        "generator=make_generator_model()\n",
        "\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "\n",
        "\n",
        "gen_loss_epoch=[]\n",
        "disc_loss_epoch=[]\n",
        "plot_distribution(real_data=X,generated_data=Xhat,discriminator=discriminator )\n",
        "print(\"epoch\",0)\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    #data for the true distribution of your real data samples training ste\n",
        "    x = tf.random.normal((BATCH_SIZE,1),mean=10,stddev=1.0)\n",
        "    #random samples it was found if you increase the standard deviation, you get better results\n",
        "    z= tf.random.normal([BATCH_SIZE, noise_dim],mean=0,stddev=10)\n",
        "    # needed to compute the gradients for a list of variables.\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        #generated sample\n",
        "        xhat = generator(z, training=True)\n",
        "        #the output of the discriminator for real data\n",
        "        real_output = discriminator(x, training=True)\n",
        "        #the output of the discriminator  data\n",
        "        fake_output = discriminator(xhat, training=True)\n",
        "        #loss for each\n",
        "        gen_loss= generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "    # Compute the gradients for gen_loss and generator\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    # Compute the gradients for gen_loss and discriminator\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "    # Ask the optimizer to apply the processed gradients\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "  # Save and display the generator and discriminator if the performance increases\n",
        "    if abs(0.5-get_accuracy(x,xhat))<epsilon:\n",
        "        epsilon=abs(0.5-get_accuracy(x,xhat))\n",
        "        generator.save('generator.keras')\n",
        "        discriminator.save('discriminator.keras')\n",
        "        print(get_accuracy(x,xhat))\n",
        "        plot_distribution(real_data=X,generated_data=xhat,discriminator=discriminator )\n",
        "        print(\"epoch\",epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9oTqAeI9j9H"
      },
      "source": [
        "For more on training GANs check out the following <a href=\"https://jonathan-hui.medium.com/gan-why-it-is-so-hard-to-train-generative-advisory-networks-819a86b3750b?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMGPXX0XCEEN72-2022-01-01\">blog</a>. We can display the best performing model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOQxRmmg9j9H"
      },
      "outputs": [],
      "source": [
        "generator=make_generator_model()\n",
        "generator= models.load_model('generator.keras')\n",
        "xhat=generator(z)\n",
        "discriminator=models.load_model('discriminator.keras')\n",
        "plot_distribution(real_data=X,generated_data=xhat,discriminator=discriminator )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoMCvbTl9j9H"
      },
      "source": [
        "----\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf2KAoDq9j9H"
      },
      "source": [
        "In the content above, you learned about the working mechanics of Generative Adversarial Networks (GANs) and their various applications, such as Image Generation. However, GANs have also been known to be unstable to train, and often, the generated images suffer from being noisy and incomprehensible.\n",
        "\n",
        "For a improved result in the case example, we are applying Convolutional Neural Networks to GANS. They are called Deep Convolutional Generative Adversarial Networks (DCGANs).\n",
        "We will build and train DCGANs in the following content, using several approaches introduced in the original <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX0XCEEN/papers/1511.06434.pdf\">DCGANs paper</a>.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he1yDDUm9j9H"
      },
      "source": [
        "----\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_b6IkAm9j9H"
      },
      "source": [
        "## Deep Convolutional Generative Adversarial Networks (DCGANs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQykrLW59j9I"
      },
      "source": [
        "### Case background\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL-G76xv9j9I"
      },
      "source": [
        "In the case example, you work for an online anime video game company; the company would like to create a unique anime avatar for a game for each player. As there are millions of players, you must use a DCGANs to create each character.\n",
        "\n",
        "The proposed approaches are summarized here:\n",
        "\n",
        "- Replace any pooling layers with **strided convolutions (discriminator)** and **fractional-strided\n",
        "convolutions (generator)**.\n",
        "- Use **batchnorm** in both the generator and the discriminator.\n",
        "- **Remove fully connected hidden layers** for deeper architectures.\n",
        "- Use **ReLU** activation in generator for all layers except for the output, which uses **Tanh**.\n",
        "- Use **LeakyReLU** activation in the discriminator for all layers except for the output, which uses **Sigmoid**.\n",
        "- Use **Adam optimizer**.  \n",
        "\n",
        "These approaches will result in more stable training of deeper generative models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g-Zsz4w9j9I"
      },
      "source": [
        "### Loading the Dataset\n",
        "\n",
        "We will mainly work with the Anime Face dataset from [Kaggle](https://www.kaggle.com/datasets/splcher/animefacedataset?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMGPXX0XCEEN72-2022-01-01). The original dataset has 63,632 \"high-quality\" anime faces, but to make the models train faster in this lab, we randomly sampled 20,000 images and prepared a dataset called `cartoon_20000`.\n",
        "\n",
        "Let's download the smaller dataset using the Skills Network library's `prepare` function:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iat3tGzw9j9I"
      },
      "outputs": [],
      "source": [
        "dataset_url=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML311-Coursera/labs/Module6/cartoon_20000.zip\"\n",
        "await skillsnetwork.prepare(dataset_url, overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oQAawRQj6uz"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RunACde6j6u0"
      },
      "source": [
        "Support for third party widgets will remain active for the duration of the session. To disable support:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G33C27a8j6u0"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "output.disable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWvVKQ6dCBFp"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Un1zTIOQDW4e"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "output.disable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubGbr_AtDYJp"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfjtfGZoCBFq"
      },
      "source": [
        "Support for third party widgets will remain active for the duration of the session. To disable support:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ujf_wmKiCBFq"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "output.disable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7T-vr2z9j9I"
      },
      "source": [
        "The Anime Face or the Cartoon images are stored in the `cartoon_2000` folder in your current working directory. As a preprocessing step, we have removed any files that are not proper image formats (based on the file extensions) and any duplicate images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A94aiGN99j9I"
      },
      "source": [
        "### Creating Data Generator\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAV_9tBf9j9I"
      },
      "source": [
        "First, we declare some properties of our images, including image height, image width, and batch size.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwc8hYWq9j9J"
      },
      "outputs": [],
      "source": [
        "img_height, img_width, batch_size=64,64,128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khyyhtCa9j9J"
      },
      "source": [
        "Next, we create a Keras <code>image_dataset_from_directory</code> object with a specified image directory and the parameters are defined as above. This process may take some time:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djC2M3pc9j9K"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(directory='cartoon_20000',\n",
        "                                                       image_size=(img_height, img_width),\n",
        "                                                       batch_size=batch_size,\n",
        "                                                       label_mode=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfxcOSa39j9K"
      },
      "source": [
        "The `train_ds` we defined is a `tf.data.Dataset` that yields batches of images with `image_size = (64, 64)` from the directory specified or subdirectories (if any).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4MXHhKV9j9K"
      },
      "source": [
        "**(OPTIONAL)** If you are running this notebook locally and you have multiple cores, then we can use the runtime to tune the value dynamically at runtime as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2_sRios9j9L"
      },
      "outputs": [],
      "source": [
        "#AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "#train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdZcNH_b9j9L"
      },
      "source": [
        "We apply the Lambda function on `train_ds` to normalize the pixel values of all the input images from $[0, 255]$ to $[-1, 1]$:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4NIvZCp9j9L"
      },
      "outputs": [],
      "source": [
        "normalization_layer = layers.Rescaling(scale= 1./127.5, offset=-1)\n",
        "normalized_ds = train_ds.map(lambda x: normalization_layer(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WdR30if9j9L"
      },
      "source": [
        "Let's take one batch of images for displaying:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52EEyOm49j9L"
      },
      "outputs": [],
      "source": [
        "images=train_ds.take(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htl11Tlb9j9M"
      },
      "source": [
        "Convert the batch dimension to the indexes in a list:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFYaq6NW9j9M"
      },
      "outputs": [],
      "source": [
        "X=[x for x in images]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtOFUFQh9j9M"
      },
      "source": [
        "We can then plot the first five images in the batch using the function   ```plot_array```:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkqKN2TQ9j9M"
      },
      "outputs": [],
      "source": [
        "plot_array(X[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqF4F1oQ9j9M"
      },
      "source": [
        "###  Generator and Discriminator (for DCGANs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2aGAjUC9j9M"
      },
      "source": [
        "___Building the Generator___\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VP_qN1a9j9M"
      },
      "source": [
        "The Generator is comprised of several layers of transposed convolution, the opposite of convolution operations.\n",
        "\n",
        "- Each Conv2DTranspose layer (except the final layer) is followed by a Batch Normalization layer and a **Relu activation**; for more implementation details, check out <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX0XCEEN/papers/1511.06434.pdf\">[2]</a>.\n",
        "- The final transpose convolution layer has three output channels since the output needs to be a color image. We use the **Tanh activation** in the final layer.\n",
        "\n",
        "See the illustration of the architecture from <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX0XCEEN/papers/1511.06434.pdf\">[2]</a> below.\n",
        "\n",
        "<center><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX0XCEEN/images/generator.png\" alt=\"generator image\" width=\"80%\"></center>\n",
        "\n",
        "\n",
        "We build the Generator network by using the parameter values from <a href=\"https://learnopencv.com/deep-convolutional-gan-in-pytorch-and-tensorflow/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMGPXX0XCEEN72-2022-01-01\" >[3]<a>.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXOatyTu9j9N"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Model\n",
        "\n",
        "def make_generator():\n",
        "    # Create input layer explicitly\n",
        "    inputs = Input(shape=(1, 1, 100), name='input_layer')\n",
        "\n",
        "    # Block 1: input is latent vector -> 4x4x512\n",
        "    x = Conv2DTranspose(64 * 8, kernel_size=4, strides=4, padding='same',\n",
        "                       kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02),\n",
        "                       use_bias=False, name='conv_transpose_1')(inputs)\n",
        "    x = BatchNormalization(momentum=0.1, epsilon=0.8, center=1.0, scale=0.02, name='bn_1')(x)\n",
        "    x = ReLU(name='relu_1')(x)\n",
        "\n",
        "    # Block 2: 4x4x512 -> 8x8x256\n",
        "    x = Conv2DTranspose(64 * 4, kernel_size=4, strides=2, padding='same',\n",
        "                       kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02),\n",
        "                       use_bias=False, name='conv_transpose_2')(x)\n",
        "    x = BatchNormalization(momentum=0.1, epsilon=0.8, center=1.0, scale=0.02, name='bn_2')(x)\n",
        "    x = ReLU(name='relu_2')(x)\n",
        "\n",
        "    # Block 3: 8x8x256 -> 16x16x128\n",
        "    x = Conv2DTranspose(64 * 2, kernel_size=4, strides=2, padding='same',\n",
        "                       kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02),\n",
        "                       use_bias=False, name='conv_transpose_3')(x)\n",
        "    x = BatchNormalization(momentum=0.1, epsilon=0.8, center=1.0, scale=0.02, name='bn_3')(x)\n",
        "    x = ReLU(name='relu_3')(x)\n",
        "\n",
        "    # Block 4: 16x16x128 -> 32x32x64\n",
        "    x = Conv2DTranspose(64 * 1, kernel_size=4, strides=2, padding='same',\n",
        "                       kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02),\n",
        "                       use_bias=False, name='conv_transpose_4')(x)\n",
        "    x = BatchNormalization(momentum=0.1, epsilon=0.8, center=1.0, scale=0.02, name='bn_4')(x)\n",
        "    x = ReLU(name='relu_4')(x)\n",
        "\n",
        "    # Final Block: 32x32x64 -> 64x64x3\n",
        "    outputs = Conv2DTranspose(3, kernel_size=4, strides=2, padding='same',\n",
        "                            kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02),\n",
        "                            use_bias=False, activation='tanh',\n",
        "                            name='conv_transpose_5')(x)\n",
        "\n",
        "    # Create model using functional API\n",
        "    model = Model(inputs=inputs, outputs=outputs, name='generator')\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyh6nvPa9j9N"
      },
      "source": [
        "By printing the summary of the Generator architecture, we can see that the transposed convolutions **upsample** a 100-dim input vector to a high-dimensional image of size 64 x 64 x 3.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsOlMga19j9N"
      },
      "outputs": [],
      "source": [
        "gen = make_generator()\n",
        "gen.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRnLNMpy9j9N"
      },
      "source": [
        "___Building the Discriminator___\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRyK-IU09j9N"
      },
      "source": [
        "The Discriminator has five convolution layers.\n",
        "\n",
        "- All but the first and final Conv2D layers have Batch Normalization, since directly applying batchnorm to all layers could result in sample oscillation and model instability;\n",
        "- The first four Conv2D layers use the **Leaky-Relu activation** with a slope of 0.2.\n",
        "- Lastly, instead of a fully connected layer, the  output layer has a convolution layer with a **Sigmoid activation** function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htOA49Cm9j9N"
      },
      "outputs": [],
      "source": [
        "def make_discriminator():\n",
        "\n",
        "    model=Sequential()\n",
        "\n",
        "    # Block 1: input is 64 x 64 x (3)\n",
        "    model.add(Input(shape=(64, 64, 3), name='input_layer'))\n",
        "    model.add(Conv2D(64, kernel_size=4, strides= 2, padding='same', kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02), use_bias=False, name='conv_1'))\n",
        "    model.add(LeakyReLU(0.2, name='leaky_relu_1'))\n",
        "\n",
        "    # Block 2: input is 32 x 32 x (64)\n",
        "    model.add(Conv2D(64 * 2, kernel_size=4, strides= 2, padding='same', kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02), use_bias=False, name='conv_2'))\n",
        "    model.add(BatchNormalization(momentum=0.1,  epsilon=0.8, center=1.0, scale=0.02, name='bn_1'))\n",
        "    model.add(LeakyReLU(0.2, name='leaky_relu_2'))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(64 * 4, 4, 2, padding='same', kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02), use_bias=False, name='conv_3'))\n",
        "    model.add(BatchNormalization(momentum=0.1,  epsilon=0.8, center=1.0, scale=0.02, name='bn_2'))\n",
        "    model.add(LeakyReLU(0.2, name='leaky_relu_3'))\n",
        "\n",
        "\n",
        "    #Block 4\n",
        "    model.add(Conv2D(64 * 8, 4, 2, padding='same', kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02), use_bias=False, name='conv_4'))\n",
        "    model.add(BatchNormalization(momentum=0.1,  epsilon=0.8, center=1.0, scale=0.02, name='bn_3'))\n",
        "    model.add(LeakyReLU(0.2, name='leaky_relu_4'))\n",
        "\n",
        "\n",
        "    #Block 5\n",
        "    model.add(Conv2D(1, 4, 2,padding='same', kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02), use_bias=False,\n",
        "                     activation='sigmoid', name='conv_5'))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6x6fjSX9j9N"
      },
      "source": [
        "By printing the summary of the Discriminator architecture, we can see that the strided convolutions **downsample** an input image of size 64 x 64 x 3.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vw6tTZOq9j9O"
      },
      "outputs": [],
      "source": [
        "disc = make_discriminator()\n",
        "disc.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwFrACuI9j9O"
      },
      "source": [
        "### Defining Loss Functions\n",
        "\n",
        "As we discussed in the previous section, the min-max optimization problem can be formulated by minimizing the cross entropy loss for the Generator and Discriminator.  \n",
        "\n",
        "The `cross_entropy` object is the Binary Cross Entropy loss that will be used to model the objectives of the two networks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZV-KZE9a9j9O"
      },
      "outputs": [],
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iJWBrdU9j9O"
      },
      "outputs": [],
      "source": [
        "def generator_loss(Xhat):\n",
        "    return cross_entropy(tf.ones_like(Xhat), Xhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khMduOKY9j9O"
      },
      "outputs": [],
      "source": [
        "def discriminator_loss(X, Xhat):\n",
        "    real_loss = cross_entropy(tf.ones_like(X), X)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(Xhat), Xhat)\n",
        "    total_loss = 0.5*(real_loss + fake_loss)\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wW84r6ye9j9O"
      },
      "source": [
        "### Defining Optimizers\n",
        "\n",
        "We create two Adam optimizers for the discriminator and the generator, respectively. We pass the following arguments to the optimizers:\n",
        "\n",
        "- learning rate of 0.0002.\n",
        "- beta coefficients $\\beta_1 = 0.5$ and $\\beta_2 = 0.999$, which are responsible for computing the running averages of the gradients during backpropagation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElT6CCUy9j9O"
      },
      "outputs": [],
      "source": [
        "\n",
        "learning_rate = 0.0002\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0002, beta_1 = 0.5, beta_2 = 0.999 )\n",
        "\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0002, beta_1 = 0.5, beta_2 = 0.999 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB604ohX9j9P"
      },
      "source": [
        "### Create Train Step Function\n",
        "\n",
        "As this lab is more computationally intensive than the last lab, we convert the training step into a function and then use the  @tf.function decorator, which allows the function to be \"compiled\" into a **callable TensorFlow graph**. This will speed up the training; for more information, read <a href=\"https://www.tensorflow.org/guide/function?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMGPXX0XCEEN72-2022-01-01\">here </a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2AZebKM9j9P"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "\n",
        "def train_step(X):\n",
        "\n",
        "    #random samples it was found if you increase the  stander deviation, you get better results\n",
        "    z= tf.random.normal([BATCH_SIZE, 1, 1, latent_dim])\n",
        "      # needed to compute the gradients for a list of variables.\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        #generated sample\n",
        "        xhat = generator(z, training=True)\n",
        "        #the output of the discriminator for real data\n",
        "        real_output = discriminator(X, training=True)\n",
        "        #the output of the discriminator for fake data\n",
        "        fake_output = discriminator(xhat, training=True)\n",
        "\n",
        "        #loss for each\n",
        "        gen_loss= generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "      # Compute the gradients for gen_loss and generator\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    # Compute the gradients for gen_loss and discriminator\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "    # Ask the optimizer to apply the processed gradients\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOC2-fV29j9P"
      },
      "source": [
        "Don't be intimidated by the code above, here is a summary of what a train step accomplishes:\n",
        "\n",
        "- First, we sample `z`, a batch of noise vectors from a normal distribution ($\\mu = 1, \\sigma = 1$) and feed it to the Generator.\n",
        "- The Generator produces generated or \"fake\" images `xhat`.\n",
        "- We feed real images `X` and fake images `xhat` to the Discriminator and obtain `real_output` and `fake_output` respectively as the scores.\n",
        "- We calculate Generator loss `gen_loss` using the `fake_output` from Discriminator since we want the fake images to fool the Discriminator as much as possible.\n",
        "- We calculate Discriminator loss `disc_loss` using both the `real_output` and `fake_output` since we want the Discriminator to distinguish the two as much as possible.\n",
        "- We calculate `gradients_of_generator` and  `gradients_of_discriminator` based on the losses obtained.\n",
        "- Finally, we update the Generator and Discriminator by letting their respective optimizers apply the processed gradients on the trainable model parameters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoTrdxkv9j9P"
      },
      "source": [
        "We can transform the random noise using the generator. As the generator is not trained yet, the output appears to be noises:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XhEbY3b9j9P"
      },
      "outputs": [],
      "source": [
        "generator= make_generator()\n",
        "BATCH_SIZE=128\n",
        "\n",
        "latent_dim=100\n",
        "noise = tf.random.normal([BATCH_SIZE, 1, 1, latent_dim])\n",
        "Xhat=generator(noise,training=False)\n",
        "plot_array(Xhat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7B6iETk9j9P"
      },
      "source": [
        "### Training DCGANs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0hKaAHU9j9Q"
      },
      "source": [
        "As this method is computationally intensive, we will train the model for one epoch and then use the generator to produce artificial images.\n",
        "\n",
        "__Even 1 epoch in DCGANs training takes long time.__ You can __stop the training__ here and import the pre-trained model following the instruction below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDIct_xl9j9Q"
      },
      "outputs": [],
      "source": [
        "epochs=1\n",
        "\n",
        "discriminator=make_discriminator()\n",
        "\n",
        "generator= make_generator()\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    #data for the true distribution of your real data samples training ste\n",
        "    start = time.time()\n",
        "    i=0\n",
        "    for X in tqdm(normalized_ds, desc=f\"epoch {epoch+1}\", total=len(normalized_ds)):\n",
        "\n",
        "        i+=1\n",
        "        if i%1000:\n",
        "            print(\"epoch {}, iteration {}\".format(epoch+1, i))\n",
        "\n",
        "        train_step(X)\n",
        "\n",
        "\n",
        "    noise = tf.random.normal([BATCH_SIZE, 1, 1, latent_dim])\n",
        "    Xhat=generator(noise,training=False)\n",
        "    X=[x for x in normalized_ds]\n",
        "    print(\"orignal images\")\n",
        "    plot_array(X[0])\n",
        "    print(\"generated images\")\n",
        "    plot_array(Xhat)\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOW8lWTc9j9Q"
      },
      "source": [
        "As you can see that, with only one epoch of training and a reduced number of training images, our GAN didn't learn much information, and thus, the generator wasn't able to produce images that make sense to human eyes. There are two quick actions you can take to try to improve the results:\n",
        "\n",
        "1. Re-train the GAN using the full dataset that has 63,632 images.\n",
        "    - To do so, simply go back to the **Loading the Dataset** section in **DCGANs**, replace the url of the dataset with \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML311-Coursera/labs/Module5/L2/cartoon_data.tgz\", change the `directory` argument in `tf.keras.utils.image_dataset_from_directory` to `'cartoon_data'` in **Creating data generator** section and re-run all the cells.\n",
        "    - Note that using more training data does allows the model to learn better and perform better, but it will result in longer training time! **With 63K training images and batch size of 128, your model will train for ~497 iterations.**\n",
        "\n",
        "\n",
        "2. Use a pre-trained generator model to generate images.\n",
        "    - You don't need to experience the training time at all!\n",
        "    - Proceed to the next subsection to load a pre-trained model, and you will see that the generator trained with 150 epochs can produce almost realistic anime faces.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW56oDbt9j9Q"
      },
      "source": [
        "___Loading Pre-trained model (150 epochs)___\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtLSaxI19j9Q"
      },
      "source": [
        "As you saw, training a GAN with only one epoch takes quite a long time. If we want to evaluate the performance of a fully trained and optimized GAN, we would need to increase the number of epochs.\n",
        "Thus, to help you **avoid extremely long training time** in this lab, we will just **download the pre-trained Generator network parameters** and then use Kera `load_model` function to obtain a **pre-trained Generator**, which we will use to generate images directly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDnCIXMT9j9Q"
      },
      "outputs": [],
      "source": [
        "generator_url=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX0XCEEN/data/generator.tar\"\n",
        "await skillsnetwork.prepare(generator_url, overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uf4AtcqIkjSB"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTtIs_2SkjSC"
      },
      "source": [
        "Support for third party widgets will remain active for the duration of the session. To disable support:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bdd9NlfkjSC"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "output.disable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wC1fDB1JkiW1"
      },
      "source": [
        "Support for third party widgets will remain active for the duration of the session. To disable support:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeynltuwkiW2"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsLogOQekhrF"
      },
      "source": [
        "Support for third party widgets will remain active for the duration of the session. To disable support:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrcErhgUkhrG"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "output.disable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFazJLaNkbDg"
      },
      "source": [
        "Support for third party widgets will remain active for the duration of the session. To disable support:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Aq79gELkyUz"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9S2-EZykbDh"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "output.disable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2G6ATHgkal_"
      },
      "source": [
        "Support for third party widgets will remain active for the duration of the session. To disable support:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9zJyhhW9j9Q"
      },
      "source": [
        "Load the generator:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNTSiIxz9j9R"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "full_generator=load_model(\"generator.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AljB7UhL9j9R"
      },
      "source": [
        "Let's generate several images using the fully trained Generator and display them:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7Gl1Nw-9j9R"
      },
      "outputs": [],
      "source": [
        "# Create noise\n",
        "latent_dim = 100\n",
        "noise = tf.random.normal([200, 1, 1, latent_dim])\n",
        "\n",
        "# Use the new generator 'gen' instead of 'full_generator'\n",
        "Xhat = gen(noise, training=False)  # Use 'gen' here, not 'full_generator'\n",
        "plot_array(Xhat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bU3rXoF-9j9R"
      },
      "source": [
        "## Explore Latent Variables\n",
        "\n",
        "Values of $\\mathbf{z}$ that are relatively close together will produce similar images. For example, we can assigns elements of $\\mathbf{z}$ close values such as $[1,0.8,..,0.4]$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OProCsq9j9R"
      },
      "outputs": [],
      "source": [
        "for c in [1,0.8,0.6,0.4]:\n",
        "    Xhat=gen(c*tf.ones([1, 1, 1, latent_dim]),training=False) # latent_dim = 100 defined previously\n",
        "    plot_array(Xhat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdJSJXYz9j9R"
      },
      "source": [
        "### Exercise 1\n",
        "\n",
        "Plot the generated images by the Generator with elements of $\\mathbf{z}$ equal $[-1,-0.8,-0.6,-0.4]$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xChWsATb9j9S"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "for c in [1, 0.8, 0.6, 0.4]:\n",
        "    # Create noise with the desired shape (5000, 1) directly\n",
        "    noise = -c * tf.ones([5000, 1])\n",
        "\n",
        "    # OR, if you need to start with a (1, 1, 1, latent_dim) shape and then reshape:\n",
        "    # 1. Create initial noise\n",
        "    # initial_noise = -c * tf.ones([1, 1, 1, latent_dim])\n",
        "    # 2. Repeat the initial noise along a new dimension to reach 5000 elements\n",
        "    # noise = tf.repeat(initial_noise, repeats=[500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owxab62B9j9S"
      },
      "source": [
        "<details>\n",
        "    <summary>Click here for Solution</summary>\n",
        "\n",
        "```python\n",
        "for c in [1,0.8,0.6,0.4]:\n",
        "    Xhat=full_generator(-c*tf.ones([1, 1, 1, latent_dim]),training=False)\n",
        "    plot_array(Xhat)\n",
        " ```   \n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD-Sa0Ca9j9S"
      },
      "source": [
        "We can see how changing the latent variable changes the generated image. Here we alter more and more subsequent values of $\\mathbf{z}$ from 1 to -1; we see the images change accordingly; this is evident in the anime character's hair color:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcuDatR39j9S"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "z = np.ones((1, 1, 1, latent_dim))\n",
        "for n in range(10):\n",
        "    z[0, 0, 0, 0:10 * n] = -1\n",
        "\n",
        "    # Reshape z to (1, 1, 1, latent_dim) before passing to the generator\n",
        "    # The original shape of z is (1, 1, 1, latent_dim)\n",
        "    # This line reshapes it to (1, 1, 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjrvnIeU9j9S"
      },
      "source": [
        "### Exercise 2\n",
        "\n",
        "Repeat the above procedure but set the latent variable $z[0, 0, 0, 0:20*n] = -0.5*n$ each time `for n in range(5)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_CVQ0ou9j9T"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "z = np.ones((1, 1, 1, latent_dim))\n",
        "for n in range(10):\n",
        "   z[0, 0, 0, 0:20*n]=-0.5*n\n",
        "\n",
        "    # Reshape z to (1, 1, 1, latent_dim) before passing to the generator\n",
        "    # The original shape of z is (1, 1, 1, latent_dim)\n",
        "    # This line reshapes it to (1, 1, 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ti0h-0E9j9T"
      },
      "source": [
        "<details>\n",
        "    <summary>Click here for Solution</summary>\n",
        "\n",
        "```python\n",
        "z=np.ones( (1, 1, 1, latent_dim))\n",
        "for n in range(5):\n",
        "\n",
        "    z[0, 0, 0, 0:20*n]=-0.5*n\n",
        "\n",
        "    Xhat=full_generator(z,training=False)\n",
        "\n",
        "    plot_array(Xhat)\n",
        "    \n",
        "\n",
        " ```   \n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVS8c7Gc9j9T"
      },
      "source": [
        "We can also hold some of the elements of $\\mathbf{z}$ constant and randomly change others. Here, we set the first 20 elements to one and randomly change the rest. We see that all through the images change, the hair color remains light.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cP4Lrs_9j9T"
      },
      "outputs": [],
      "source": [
        "for n in range(10):\n",
        "    # Create a latent vector with shape (1, latent_dim)\n",
        "    z = np.random.normal(0, 1, (1, latent_dim))\n",
        "\n",
        "    # Reshape z to (1, 1) before passing to the generator\n",
        "    # The error indicates that the model expects input shape (None, 1)\n",
        "    # and you are providing (1, 100) - Reshape to match.\n",
        "    z = z.reshape(1, 1)\n",
        "\n",
        "    Xhat = full_generator(z, training=False)\n",
        "\n",
        "    # Reshape Xhat to the expected image dimensions\n",
        "    image_shape = (28, 28)  # Replace with the actual image dimensions\n",
        "    # The output of the generator might have more dimensions.\n",
        "    # Assuming the output shape is (1, 28, 28, 1), adjust as needed:\n",
        "    Xhat_reshaped = Xhat.numpy().reshape(image_shape)\n",
        "\n",
        "    plot_array(Xhat_reshaped)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZ6UBifMieb_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmGJ8lUW9j9T"
      },
      "source": [
        "### Exercise 3\n",
        "\n",
        "Repeat the procedure above, but set the elements of $\\mathbf{z}$ from index 0 to 35 to -1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDtleTnl9j9T"
      },
      "outputs": [],
      "source": [
        "for n in range(10):\n",
        "    # Create a latent vector with shape (1, latent_dim)\n",
        "    z = np.random.normal(0, 1, (1, latent_dim))\n",
        "\n",
        "    # Modify the first 35 elements of the latent vector\n",
        "    z[0, 0:35] = -1\n",
        "\n",
        "    # Pass the correctly shaped latent vector to the generator\n",
        "    Xhat = full_generator(z, training=False)\n",
        "\n",
        "    # Reshape Xhat to the expected image dimensions\n",
        "    image_shape = (28, 28)  # Replace with the actual image dimensions\n",
        "    # The output of the generator might have more dimensions.\n",
        "    # Assuming the output shape is (1, 28, 28, 1), adjust as needed:\n",
        "    Xhat_reshaped = Xhat.numpy().reshape(image_shape)\n",
        "\n",
        "    plot_array(Xhat_reshaped)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au0CQ6Tr9j9U"
      },
      "source": [
        "<details>\n",
        "    <summary>Click here for Solution</summary>\n",
        "\n",
        "```python\n",
        "\n",
        "for n in range(10):\n",
        "    z=np.random.normal(0, 1, (1, 1, 1, latent_dim))\n",
        "\n",
        "    z[0,0,0,0:35]=-1\n",
        "\n",
        "    Xhat=full_generator(z,training=False)\n",
        "\n",
        "    plot_array(Xhat)\n",
        "    \n",
        "\n",
        " ```   \n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIlJR_zq9j9U"
      },
      "source": [
        "__Thank you for completing this lab!__\n",
        "<center><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX0XCEEN/images/unknown5.jpeg\" width=\"500px\"></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyy70gUZ9j9U"
      },
      "source": [
        "----\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "bU3rXoF-9j9R"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}